<!DOCTYPE html>
<html>
<head>
<title>README.md</title>
<meta http-equiv="Content-type" content="text/html;charset=UTF-8">

<style>
/* https://github.com/microsoft/vscode/blob/master/extensions/markdown-language-features/media/markdown.css */
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

body {
	font-family: var(--vscode-markdown-font-family, -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif);
	font-size: var(--vscode-markdown-font-size, 14px);
	padding: 0 26px;
	line-height: var(--vscode-markdown-line-height, 22px);
	word-wrap: break-word;
}

#code-csp-warning {
	position: fixed;
	top: 0;
	right: 0;
	color: white;
	margin: 16px;
	text-align: center;
	font-size: 12px;
	font-family: sans-serif;
	background-color:#444444;
	cursor: pointer;
	padding: 6px;
	box-shadow: 1px 1px 1px rgba(0,0,0,.25);
}

#code-csp-warning:hover {
	text-decoration: none;
	background-color:#007acc;
	box-shadow: 2px 2px 2px rgba(0,0,0,.25);
}

body.scrollBeyondLastLine {
	margin-bottom: calc(100vh - 22px);
}

body.showEditorSelection .code-line {
	position: relative;
}

body.showEditorSelection .code-active-line:before,
body.showEditorSelection .code-line:hover:before {
	content: "";
	display: block;
	position: absolute;
	top: 0;
	left: -12px;
	height: 100%;
}

body.showEditorSelection li.code-active-line:before,
body.showEditorSelection li.code-line:hover:before {
	left: -30px;
}

.vscode-light.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(0, 0, 0, 0.15);
}

.vscode-light.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(0, 0, 0, 0.40);
}

.vscode-light.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-dark.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 255, 255, 0.4);
}

.vscode-dark.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 255, 255, 0.60);
}

.vscode-dark.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-high-contrast.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 160, 0, 0.7);
}

.vscode-high-contrast.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 160, 0, 1);
}

.vscode-high-contrast.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

img {
	max-width: 100%;
	max-height: 100%;
}

a {
	text-decoration: none;
}

a:hover {
	text-decoration: underline;
}

a:focus,
input:focus,
select:focus,
textarea:focus {
	outline: 1px solid -webkit-focus-ring-color;
	outline-offset: -1px;
}

hr {
	border: 0;
	height: 2px;
	border-bottom: 2px solid;
}

h1 {
	padding-bottom: 0.3em;
	line-height: 1.2;
	border-bottom-width: 1px;
	border-bottom-style: solid;
}

h1, h2, h3 {
	font-weight: normal;
}

table {
	border-collapse: collapse;
}

table > thead > tr > th {
	text-align: left;
	border-bottom: 1px solid;
}

table > thead > tr > th,
table > thead > tr > td,
table > tbody > tr > th,
table > tbody > tr > td {
	padding: 5px 10px;
}

table > tbody > tr + tr > td {
	border-top: 1px solid;
}

blockquote {
	margin: 0 7px 0 5px;
	padding: 0 16px 0 10px;
	border-left-width: 5px;
	border-left-style: solid;
}

code {
	font-family: Menlo, Monaco, Consolas, "Droid Sans Mono", "Courier New", monospace, "Droid Sans Fallback";
	font-size: 1em;
	line-height: 1.357em;
}

body.wordWrap pre {
	white-space: pre-wrap;
}

pre:not(.hljs),
pre.hljs code > div {
	padding: 16px;
	border-radius: 3px;
	overflow: auto;
}

pre code {
	color: var(--vscode-editor-foreground);
	tab-size: 4;
}

/** Theming */

.vscode-light pre {
	background-color: rgba(220, 220, 220, 0.4);
}

.vscode-dark pre {
	background-color: rgba(10, 10, 10, 0.4);
}

.vscode-high-contrast pre {
	background-color: rgb(0, 0, 0);
}

.vscode-high-contrast h1 {
	border-color: rgb(0, 0, 0);
}

.vscode-light table > thead > tr > th {
	border-color: rgba(0, 0, 0, 0.69);
}

.vscode-dark table > thead > tr > th {
	border-color: rgba(255, 255, 255, 0.69);
}

.vscode-light h1,
.vscode-light hr,
.vscode-light table > tbody > tr + tr > td {
	border-color: rgba(0, 0, 0, 0.18);
}

.vscode-dark h1,
.vscode-dark hr,
.vscode-dark table > tbody > tr + tr > td {
	border-color: rgba(255, 255, 255, 0.18);
}

</style>

<style>
/* Tomorrow Theme */
/* http://jmblog.github.com/color-themes-for-google-code-highlightjs */
/* Original theme - https://github.com/chriskempson/tomorrow-theme */

/* Tomorrow Comment */
.hljs-comment,
.hljs-quote {
	color: #8e908c;
}

/* Tomorrow Red */
.hljs-variable,
.hljs-template-variable,
.hljs-tag,
.hljs-name,
.hljs-selector-id,
.hljs-selector-class,
.hljs-regexp,
.hljs-deletion {
	color: #c82829;
}

/* Tomorrow Orange */
.hljs-number,
.hljs-built_in,
.hljs-builtin-name,
.hljs-literal,
.hljs-type,
.hljs-params,
.hljs-meta,
.hljs-link {
	color: #f5871f;
}

/* Tomorrow Yellow */
.hljs-attribute {
	color: #eab700;
}

/* Tomorrow Green */
.hljs-string,
.hljs-symbol,
.hljs-bullet,
.hljs-addition {
	color: #718c00;
}

/* Tomorrow Blue */
.hljs-title,
.hljs-section {
	color: #4271ae;
}

/* Tomorrow Purple */
.hljs-keyword,
.hljs-selector-tag {
	color: #8959a8;
}

.hljs {
	display: block;
	overflow-x: auto;
	color: #4d4d4c;
	padding: 0.5em;
}

.hljs-emphasis {
	font-style: italic;
}

.hljs-strong {
	font-weight: bold;
}
</style>

<style>
/*
 * Markdown PDF CSS
 */

 body {
	font-family: -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif, "Meiryo";
	padding: 0 12px;
}

pre {
	background-color: #f8f8f8;
	border: 1px solid #cccccc;
	border-radius: 3px;
	overflow-x: auto;
	white-space: pre-wrap;
	overflow-wrap: break-word;
}

pre:not(.hljs) {
	padding: 23px;
	line-height: 19px;
}

blockquote {
	background: rgba(127, 127, 127, 0.1);
	border-color: rgba(0, 122, 204, 0.5);
}

.emoji {
	height: 1.4em;
}

code {
	font-size: 14px;
	line-height: 19px;
}

/* for inline code */
:not(pre):not(.hljs) > code {
	color: #C9AE75; /* Change the old color so it seems less like an error */
	font-size: inherit;
}

/* Page Break : use <div class="page"/> to insert page break
-------------------------------------------------------- */
.page {
	page-break-after: always;
}

</style>
<link rel="stylesheet" href="file:///Users/okmt/books/logicalbeat_md.css" type="text/css">
<script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
</head>
<body>
  <script>
    mermaid.initialize({
      startOnLoad: true,
      theme: document.body.classList.contains('vscode-dark') || document.body.classList.contains('vscode-high-contrast')
          ? 'dark'
          : 'default'
    });
  </script>
<h1 id="%E3%82%B5%E3%83%B3%E3%83%97%E3%83%AB%E3%82%A2%E3%83%97%E3%83%AA%E3%82%B1%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3%E6%A6%82%E8%A6%81">サンプルアプリケーション概要</h1>
<p>SPAのフロントエンドとREST APIのバックエンドに分かれる</p>
<p>また、スケジュール起動されるバッチアプリケーションも存在する</p>
<h1 id="eks%E6%A7%8B%E7%AF%89%E3%81%AB%E5%88%A9%E7%94%A8%E3%81%99%E3%82%8B%E3%83%84%E3%83%BC%E3%83%AB-eksctl">EKS構築に利用するツール eksctl</h1>
<p>EKSクラスターの構築および管理を行うためのOSSコマンドラインツール</p>
<p>VPC、サブネット、セキュリティグループなどを一括して構築することができる</p>
<p>本手順ではVPNでのベースリソースは先に作成しておき、EKSクラスターを構築するときにそれらのリソースIDを指定することにする</p>
<h2 id="%E3%83%99%E3%83%BC%E3%82%B9%E3%83%AA%E3%82%BD%E3%83%BC%E3%82%B9%E3%81%AE%E4%BD%9C%E6%88%90">ベースリソースの作成</h2>
<p>以下のツールをインストールしておく</p>
<ul>
<li>AWS CLI</li>
<li>eksctl</li>
<li>kubectl</li>
</ul>
<p>eks-work-base.yaml を用意してCloudFormationに食わせる</p>
<pre class="hljs"><code><div>AWSTemplateFormatVersion: '2010-09-09'

Parameters:
  ClusterBaseName:
    Type: String
    Default: eks-work

  TargetRegion:
    Type: String
    Default: ap-northeast-1

  AvailabilityZone1:
    Type: String
    Default: ap-northeast-1a

  AvailabilityZone2:
    Type: String
    Default: ap-northeast-1c

  AvailabilityZone3:
    Type: String
    Default: ap-northeast-1d

  VpcBlock:
    Type: String
    Default: 192.168.0.0/16

  WorkerSubnet1Block:
    Type: String
    Default: 192.168.0.0/24

  WorkerSubnet2Block:
    Type: String
    Default: 192.168.1.0/24

  WorkerSubnet3Block:
    Type: String
    Default: 192.168.2.0/24

Resources:
  EksWorkVPC:
    Type: AWS::EC2::VPC
    Properties:
      CidrBlock: !Ref VpcBlock
      EnableDnsSupport: true
      EnableDnsHostnames: true
      Tags:
        - Key: Name
          Value: !Sub ${ClusterBaseName}-VPC

  WorkerSubnet1:
    Type: AWS::EC2::Subnet
    Properties:
      AvailabilityZone: !Ref AvailabilityZone1
      CidrBlock: !Ref WorkerSubnet1Block
      VpcId: !Ref EksWorkVPC
      MapPublicIpOnLaunch: true
      Tags:
        - Key: Name
          Value: !Sub ${ClusterBaseName}-WorkerSubnet1

  WorkerSubnet2:
    Type: AWS::EC2::Subnet
    Properties:
      AvailabilityZone: !Ref AvailabilityZone2
      CidrBlock: !Ref WorkerSubnet2Block
      VpcId: !Ref EksWorkVPC
      MapPublicIpOnLaunch: true
      Tags:
        - Key: Name
          Value: !Sub ${ClusterBaseName}-WorkerSubnet2

  WorkerSubnet3:
    Type: AWS::EC2::Subnet
    Properties:
      AvailabilityZone: !Ref AvailabilityZone3
      CidrBlock: !Ref WorkerSubnet3Block
      VpcId: !Ref EksWorkVPC
      MapPublicIpOnLaunch: true
      Tags:
        - Key: Name
          Value: !Sub ${ClusterBaseName}-WorkerSubnet3

  InternetGateway:
    Type: AWS::EC2::InternetGateway

  VPCGatewayAttachment:
    Type: AWS::EC2::VPCGatewayAttachment
    Properties:
      InternetGatewayId: !Ref InternetGateway
      VpcId: !Ref EksWorkVPC

  WorkerSubnetRouteTable:
    Type: AWS::EC2::RouteTable
    Properties:
      VpcId: !Ref EksWorkVPC
      Tags:
        - Key: Name
          Value: !Sub ${ClusterBaseName}-WorkerSubnetRouteTable

  WorkerSubnetRoute:
    Type: AWS::EC2::Route
    Properties:
      RouteTableId: !Ref WorkerSubnetRouteTable
      DestinationCidrBlock: 0.0.0.0/0
      GatewayId: !Ref InternetGateway

  WorkerSubnet1RouteTableAssociation:
    Type: AWS::EC2::SubnetRouteTableAssociation
    Properties:
      SubnetId: !Ref WorkerSubnet1
      RouteTableId: !Ref WorkerSubnetRouteTable

  WorkerSubnet2RouteTableAssociation:
    Type: AWS::EC2::SubnetRouteTableAssociation
    Properties:
      SubnetId: !Ref WorkerSubnet2
      RouteTableId: !Ref WorkerSubnetRouteTable

  WorkerSubnet3RouteTableAssociation:
    Type: AWS::EC2::SubnetRouteTableAssociation
    Properties:
      SubnetId: !Ref WorkerSubnet3
      RouteTableId: !Ref WorkerSubnetRouteTable

Outputs:
  VPC:
    Value: !Ref EksWorkVPC

  WorkerSubnets:
    Value: !Join
      - &quot;,&quot;
      - [!Ref WorkerSubnet1, !Ref WorkerSubnet2, !Ref WorkerSubnet3]

  RouteTable:
    Value: !Ref WorkerSubnetRouteTable
</div></code></pre>
<p>リソースの作成が完了するとCREATE_IN_PROGRESSからCREATE_COMPLETEに変わる</p>
<p><img src="eks-work-base.png" alt="eks-work-base"></p>
<p>上記操作でVPCも作成済み</p>
<p><img src="vpc.png" alt="vpc"></p>
<h2 id="eks%E3%82%AF%E3%83%A9%E3%82%B9%E3%82%BF%E3%83%BC%E6%A7%8B%E7%AF%89">EKSクラスター構築</h2>
<p>ベースリソースの情報はCloudFormationの出力タブで確認可能</p>
<p><img src="eks-work-base2.png" alt="eks-work-base2"></p>
<p>WorkerSubnetsの値をメモる</p>
<p>下記のeksctlを実行する</p>
<pre class="hljs"><code><div>$ worker_subnets='上記でメモった値'
$ eksctl create cluster \
--vpc-public-subnets ${worker_subnets} \
--name eks-worker-cluster \
--version 1.25 \
--nodegroup-name eks-worker-nodegroup \
--node-type t2.small \
--nodes 2 \
--nodes-min 2 \
--nodes-max 5
</div></code></pre>
<p>出力する</p>
<pre class="hljs"><code><div>2023-06-28 15:52:47 [ℹ]  eksctl version 0.146.0
2023-06-28 15:52:47 [ℹ]  using region ap-northeast-1
2023-06-28 15:52:48 [✔]  using existing VPC (vpc-049f0f8f507a9f442) and subnets (private:map[] public:map[ap-northeast-1a:{subnet-07dfb8aef1bfc103b ap-northeast-1a 192.168.0.0/24 0 } ap-northeast-1c:{subnet-0cfacecd339eda649 ap-northeast-1c 192.168.1.0/24 0 } ap-northeast-1d:{subnet-008c65a949a8ced94 ap-northeast-1d 192.168.2.0/24 0 }])
2023-06-28 15:52:48 [!]  custom VPC/subnets will be used; if resulting cluster doesn't function as expected, make sure to review the configuration of VPC/subnets
2023-06-28 15:52:48 [ℹ]  nodegroup &quot;eks-worker-nodegroup&quot; will use &quot;&quot; [AmazonLinux2/1.25]
2023-06-28 15:52:48 [ℹ]  using Kubernetes version 1.25
2023-06-28 15:52:48 [ℹ]  creating EKS cluster &quot;eks-worker-cluster&quot; in &quot;ap-northeast-1&quot; region with managed nodes
2023-06-28 15:52:48 [ℹ]  will create 2 separate CloudFormation stacks for cluster itself and the initial managed nodegroup
2023-06-28 15:52:48 [ℹ]  if you encounter any issues, check CloudFormation console or try 'eksctl utils describe-stacks --region=ap-northeast-1 --cluster=eks-worker-cluster'
2023-06-28 15:52:48 [ℹ]  Kubernetes API endpoint access will use default of {publicAccess=true, privateAccess=false} for cluster &quot;eks-worker-cluster&quot; in &quot;ap-northeast-1&quot;
2023-06-28 15:52:48 [ℹ]  CloudWatch logging will not be enabled for cluster &quot;eks-worker-cluster&quot; in &quot;ap-northeast-1&quot;
2023-06-28 15:52:48 [ℹ]  you can enable it with 'eksctl utils update-cluster-logging --enable-types={SPECIFY-YOUR-LOG-TYPES-HERE (e.g. all)} --region=ap-northeast-1 --cluster=eks-worker-cluster'
2023-06-28 15:52:48 [ℹ]  
2 sequential tasks: { create cluster control plane &quot;eks-worker-cluster&quot;, 
    2 sequential sub-tasks: { 
        wait for control plane to become ready,
        create managed nodegroup &quot;eks-worker-nodegroup&quot;,
    } 
}
2023-06-28 15:52:48 [ℹ]  building cluster stack &quot;eksctl-eks-worker-cluster-cluster&quot;
2023-06-28 15:52:49 [ℹ]  deploying stack &quot;eksctl-eks-worker-cluster-cluster&quot;
2023-06-28 15:53:19 [ℹ]  waiting for CloudFormation stack &quot;eksctl-eks-worker-cluster-cluster&quot;
2023-06-28 15:53:49 [ℹ]  waiting for CloudFormation stack &quot;eksctl-eks-worker-cluster-cluster&quot;
2023-06-28 15:54:49 [ℹ]  waiting for CloudFormation stack &quot;eksctl-eks-worker-cluster-cluster&quot;
2023-06-28 15:55:50 [ℹ]  waiting for CloudFormation stack &quot;eksctl-eks-worker-cluster-cluster&quot;
2023-06-28 15:56:50 [ℹ]  waiting for CloudFormation stack &quot;eksctl-eks-worker-cluster-cluster&quot;
2023-06-28 15:57:50 [ℹ]  waiting for CloudFormation stack &quot;eksctl-eks-worker-cluster-cluster&quot;
2023-06-28 15:58:50 [ℹ]  waiting for CloudFormation stack &quot;eksctl-eks-worker-cluster-cluster&quot;
2023-06-28 15:59:51 [ℹ]  waiting for CloudFormation stack &quot;eksctl-eks-worker-cluster-cluster&quot;
2023-06-28 16:00:51 [ℹ]  waiting for CloudFormation stack &quot;eksctl-eks-worker-cluster-cluster&quot;
2023-06-28 16:01:51 [ℹ]  waiting for CloudFormation stack &quot;eksctl-eks-worker-cluster-cluster&quot;
2023-06-28 16:03:54 [ℹ]  building managed nodegroup stack &quot;eksctl-eks-worker-cluster-nodegroup-eks-worker-nodegroup&quot;
2023-06-28 16:03:55 [ℹ]  deploying stack &quot;eksctl-eks-worker-cluster-nodegroup-eks-worker-nodegroup&quot;
2023-06-28 16:03:55 [ℹ]  waiting for CloudFormation stack &quot;eksctl-eks-worker-cluster-nodegroup-eks-worker-nodegroup&quot;
2023-06-28 16:04:25 [ℹ]  waiting for CloudFormation stack &quot;eksctl-eks-worker-cluster-nodegroup-eks-worker-nodegroup&quot;
2023-06-28 16:04:58 [ℹ]  waiting for CloudFormation stack &quot;eksctl-eks-worker-cluster-nodegroup-eks-worker-nodegroup&quot;
2023-06-28 16:06:25 [ℹ]  waiting for CloudFormation stack &quot;eksctl-eks-worker-cluster-nodegroup-eks-worker-nodegroup&quot;
2023-06-28 16:08:01 [ℹ]  waiting for CloudFormation stack &quot;eksctl-eks-worker-cluster-nodegroup-eks-worker-nodegroup&quot;
2023-06-28 16:08:01 [ℹ]  waiting for the control plane to become ready
2023-06-28 16:08:02 [✔]  saved kubeconfig as &quot;/Users/okmt/.kube/config&quot;
2023-06-28 16:08:02 [ℹ]  no tasks
2023-06-28 16:08:02 [✔]  all EKS cluster resources for &quot;eks-worker-cluster&quot; have been created
2023-06-28 16:08:02 [ℹ]  nodegroup &quot;eks-worker-nodegroup&quot; has 2 node(s)
2023-06-28 16:08:02 [ℹ]  node &quot;ip-192-168-0-46.ap-northeast-1.compute.internal&quot; is ready
2023-06-28 16:08:02 [ℹ]  node &quot;ip-192-168-1-107.ap-northeast-1.compute.internal&quot; is ready
2023-06-28 16:08:02 [ℹ]  waiting for at least 2 node(s) to become ready in &quot;eks-worker-nodegroup&quot;
2023-06-28 16:08:02 [ℹ]  nodegroup &quot;eks-worker-nodegroup&quot; has 2 node(s)
2023-06-28 16:08:02 [ℹ]  node &quot;ip-192-168-0-46.ap-northeast-1.compute.internal&quot; is ready
2023-06-28 16:08:02 [ℹ]  node &quot;ip-192-168-1-107.ap-northeast-1.compute.internal&quot; is ready
2023-06-28 16:08:02 [ℹ]  kubectl command should work with &quot;/Users/okmt/.kube/config&quot;, try 'kubectl get nodes'
2023-06-28 16:08:02 [✔]  EKS cluster &quot;eks-worker-cluster&quot; in &quot;ap-northeast-1&quot; region is ready
</div></code></pre>
<p>このコマンド20分くらいかかるんだけど、びっくりするよね。</p>
<p>CloudFormationの進捗はUIでも確認可能</p>
<p><img src="eksctl-eks-worker-cluster-cluster.png" alt="eksctl-eks-worker-cluster-cluster"></p>
<p>上記コマンドで以下2つを作成できる</p>
<ul>
<li>EKSクラスター</li>
<li>ワーカーノード</li>
</ul>
<h2 id="kubeconfig%E3%81%AE%E8%A8%AD%E5%AE%9A">kubeconfigの設定</h2>
<p>kubeconfigはk8sクライアントのkubectlが利用する設定ファイルで接続先のk8sクラスターの接続情報を保持している</p>
<p>eksctlはEKSクラスター構築の中でkubeconfigファイルを自動的に更新してくれる</p>
<p>${USER}/.kube/config に配置されている</p>
<pre class="hljs"><code><div>$ kubectl config get-contexts
CURRENT   NAME                                                 CLUSTER                                       AUTHINFO                                             NAMESPACE
*         awscli@eks-worker-cluster.ap-northeast-1.eksctl.io   eks-worker-cluster.ap-northeast-1.eksctl.io   awscli@eks-worker-cluster.ap-northeast-1.eksctl.io

$ kubectl get nodes
NAME                                               STATUS   ROLES    AGE    VERSION
ip-192-168-0-46.ap-northeast-1.compute.internal    Ready    &lt;none&gt;   9m6s   v1.25.9-eks-0a21954
ip-192-168-1-107.ap-northeast-1.compute.internal   Ready    &lt;none&gt;   9m4s   v1.25.9-eks-0a21954
</div></code></pre>
<h2 id="eks%E3%82%AF%E3%83%A9%E3%82%B9%E3%82%BF%E3%83%BC%E3%81%AE%E5%8B%95%E4%BD%9C%E7%A2%BA%E8%AA%8D">EKSクラスターの動作確認</h2>
<p>02_nginx_k8s.yaml</p>
<pre class="hljs"><code><div>apiVersion: v1
kind: Pod
metadata:
  name: nginx-pod
  labels:
    app: nginx-app
spec:
  containers:
  - name: nginx-container
    image: nginx
    ports:
      - containerPort: 80
</div></code></pre>
<p>Podを作成</p>
<pre class="hljs"><code><div>$ kubectl apply -f 02_nginx_k8s.yaml
pod/nginx-pod created
</div></code></pre>
<p>Podの情報を取得</p>
<pre class="hljs"><code><div>$ kubectl get pods
NAME        READY   STATUS    RESTARTS   AGE
nginx-pod   1/1     Running   0          80s
</div></code></pre>
<p>ポートフォワーディングする</p>
<pre class="hljs"><code><div>$ kubectl port-forward nginx-pod 8080:80
Forwarding from 127.0.0.1:8080 -&gt; 80
Forwarding from [::1]:8080 -&gt; 80
</div></code></pre>
<p>これで http://localhost:8080 を開くとEKSクラスター上でnginxが立ち上がっている</p>
<p><img src="nginx.png" alt="nginx"></p>
<pre class="hljs"><code><div>$ kubectl delete pod nginx-pod
pod &quot;nginx-pod&quot; deleted
</div></code></pre>
<h2 id="%E3%83%87%E3%83%BC%E3%82%BF%E3%83%99%E3%83%BC%E3%82%B9%E3%81%AE%E3%82%BB%E3%83%83%E3%83%88%E3%82%A2%E3%83%83%E3%83%97">データベースのセットアップ</h2>
<p>データベース環境もCloudFormationから作成する</p>
<p>但し、作成時に下記のパラメータを設定すること</p>
<ul>
<li>EksWorkVPC: プルダウンメニュー 選択肢のうち kes-work-VPC が含まれる行</li>
<li>OpeServerRouteTable: CloudFormation -&gt; eks-work-base -&gt; 出力 -&gt; RouteTable rtb-0xxxxxxxxxxxxxx</li>
</ul>
<p>IAMも作成できるようにチェックをいれる</p>
<pre class="hljs"><code><div>AWSTemplateFormatVersion: &quot;2010-09-09&quot;

Parameters:
  EksWorkVPC:
    Type: AWS::EC2::VPC::Id

  WorkerSubnet1Block:
    Type: String
    Default: 192.168.0.0/24

  WorkerSubnet2Block:
    Type: String
    Default: 192.168.1.0/24

  WorkerSubnet3Block:
    Type: String
    Default: 192.168.2.0/24

  OpeSubnetBlock:
    Type: String
    Default: 192.168.5.0/24

  OpeServerRouteTable:
    Type: String

  ClusterBaseName:
    Type: String
    Default: eks-work

  TargetRegion:
    Type: String
    Default: ap-northeast-1

  AvailabilityZone1:
    Type: String
    Default: ap-northeast-1a

  AvailabilityZone2:
    Type: String
    Default: ap-northeast-1c

  AvailabilityZone3:
    Type: String
    Default: ap-northeast-1d

  RdsSubnet1Block:
    Type: String
    Default: 192.168.3.0/24

  RdsSubnet2Block:
    Type: String
    Default: 192.168.4.0/24

  OpeServerInstanceType:
    Type: String
    Default: t2.micro

  OpeServerImageId:
    Type: String
    Default: ami-00d101850e971728d # ap-northeast-1, SSD, Amazon Linux 2

  OpeServerVolumeSize:
    Type: Number
    Default: 8

Resources:
  RdsSubnet1:
    Type: AWS::EC2::Subnet
    Properties:
      AvailabilityZone: !Ref AvailabilityZone1
      CidrBlock: !Ref RdsSubnet1Block
      VpcId: !Ref EksWorkVPC

  RdsSubnet2:
    Type: AWS::EC2::Subnet
    Properties:
      AvailabilityZone: !Ref AvailabilityZone2
      CidrBlock: !Ref RdsSubnet2Block
      VpcId: !Ref EksWorkVPC

  RdsSecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: Security Group for RDS
      VpcId: !Ref EksWorkVPC

  RdsIngressPostgreSQLWorker1:
    Type: AWS::EC2::SecurityGroupIngress
    Properties:
      GroupId: !Ref RdsSecurityGroup
      CidrIp: !Ref WorkerSubnet1Block
      IpProtocol: tcp
      FromPort: 5432
      ToPort: 5432

  RdsIngressPostgreSQLWorker2:
    Type: AWS::EC2::SecurityGroupIngress
    Properties:
      GroupId: !Ref RdsSecurityGroup
      CidrIp: !Ref WorkerSubnet2Block
      IpProtocol: tcp
      FromPort: 5432
      ToPort: 5432

  RdsIngressPostgreSQLWorker3:
    Type: AWS::EC2::SecurityGroupIngress
    Properties:
      GroupId: !Ref RdsSecurityGroup
      CidrIp: !Ref WorkerSubnet3Block
      IpProtocol: tcp
      FromPort: 5432
      ToPort: 5432

  RdsIngressPostgreSQLOpe:
    Type: AWS::EC2::SecurityGroupIngress
    Properties:
      GroupId: !Ref RdsSecurityGroup
      CidrIp: !Ref OpeSubnetBlock
      IpProtocol: tcp
      FromPort: 5432
      ToPort: 5432

  EksWorkDB:
    Type: &quot;AWS::RDS::DBInstance&quot;
    Properties:
      DBInstanceIdentifier: eks-work-db
      Engine: postgres
      EngineVersion: 14.8
      DBInstanceClass: db.t3.micro
      AllocatedStorage: 30
      StorageType: gp2
      DBName: eksworkdb
      MasterUsername: !Join ['', ['{{resolve:secretsmanager:', !Ref RdsMasterSecret, ':SecretString:username}}' ]]
      MasterUserPassword: !Join ['', ['{{resolve:secretsmanager:', !Ref RdsMasterSecret, ':SecretString:password}}' ]]
      DBSubnetGroupName: !Ref EksWorkDBSubnetGroup
      PubliclyAccessible: false
      MultiAZ: false
      PreferredBackupWindow: 18:00-18:30
      PreferredMaintenanceWindow: sat:19:00-sat:19:30
      AutoMinorVersionUpgrade: false
      DBParameterGroupName: !Ref EksWorkDBParameterGroup
      VPCSecurityGroups:
        - !Ref RdsSecurityGroup
      CopyTagsToSnapshot: true
      BackupRetentionPeriod: 7
      DeletionProtection: false

  RdsMasterSecret:
    Type: AWS::SecretsManager::Secret
    Properties:
      GenerateSecretString:
        SecretStringTemplate: '{&quot;username&quot;: &quot;eksdbadmin&quot;}'
        GenerateStringKey: 'password'
        PasswordLength: 16
        ExcludeCharacters: '&quot;@/\'''
      Name: RdsMasterSecret

  RdsUserSecret:
    Type: AWS::SecretsManager::Secret
    Properties:
      GenerateSecretString:
        SecretStringTemplate: '{&quot;username&quot;: &quot;mywork&quot;}'
        GenerateStringKey: 'password'
        PasswordLength: 16
        ExcludeCharacters: '&quot;@/\''{}#%&amp;*&lt;&gt;[]^`|'
      Name: RdsUserSecret

  RdsSecretAttachment:
    Type: AWS::SecretsManager::SecretTargetAttachment
    Properties:
      SecretId: !Ref RdsMasterSecret
      TargetId: !Ref EksWorkDB
      TargetType: AWS::RDS::DBInstance

  EksWorkDBSubnetGroup:
    Type: AWS::RDS::DBSubnetGroup
    Properties:
      DBSubnetGroupName: subnet-group-eks-work-db
      DBSubnetGroupDescription: &quot;DB Subnet Group&quot;
      SubnetIds:
        - !Ref RdsSubnet1
        - !Ref RdsSubnet2

  EksWorkDBParameterGroup:
    Type: AWS::RDS::DBParameterGroup
    Properties:
      Family: postgres14
      Description: Parameter Group for PostgreSQL 14.8

  OpeServerSubnet:
    Type: AWS::EC2::Subnet
    Properties:
      AvailabilityZone: !Ref AvailabilityZone1
      CidrBlock: !Ref OpeSubnetBlock
      VpcId: !Ref EksWorkVPC

  OpeServerSubnetRouteTableAssociation:
    Type: AWS::EC2::SubnetRouteTableAssociation
    Properties:
      SubnetId: !Ref OpeServerSubnet
      RouteTableId: !Ref OpeServerRouteTable

  OpeServerSecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: Security Group for Ope
      VpcId: !Ref EksWorkVPC

  RdsIngressPostgreSQLFromOpe:
    Type: AWS::EC2::SecurityGroupIngress
    Properties:
      GroupId: !Ref RdsSecurityGroup
      SourceSecurityGroupId: !Ref OpeServerSecurityGroup
      IpProtocol: tcp
      FromPort: 5432
      ToPort: 5432

  OpeServerRole:
    Type: AWS::IAM::Role
    Properties:
      RoleName: !Sub ${ClusterBaseName}-OpeServerRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AmazonEC2RoleforSSM
      Path: /
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - ec2.amazonaws.com
            Action:
              - sts:AssumeRole

  OpeServerInstanceProfile:
    Type: AWS::IAM::InstanceProfile
    Properties:
      Path: /
      Roles:
        - !Ref OpeServerRole

  OpeServerEIP:
    Type: AWS::EC2::EIP
    Properties:
      Domain: vpc

  OpeServerEIPAssociation:
    Type: AWS::EC2::EIPAssociation
    Properties:
      AllocationId: !GetAtt OpeServerEIP.AllocationId
      InstanceId: !Ref OpeServerInstance

  OpeServerInstance:
    Type: AWS::EC2::Instance
    Properties:
      InstanceType: !Ref OpeServerInstanceType
      ImageId: !Ref OpeServerImageId
      BlockDeviceMappings:
        - DeviceName: /dev/xvda
          Ebs:
            VolumeType: gp2
            VolumeSize: 8
            DeleteOnTermination: true
      NetworkInterfaces:
        - SubnetId: !Ref OpeServerSubnet
          AssociatePublicIpAddress: false
          GroupSet:
            - !Ref OpeServerSecurityGroup
          DeviceIndex: 0
          DeleteOnTermination: true
      DisableApiTermination: false
      IamInstanceProfile: !Ref OpeServerInstanceProfile
      UserData:
        Fn::Base64:
          !Sub |
          #!/bin/bash
          set -o xtrace
          yum install -y https://s3.amazonaws.com/ec2-downloads-windows/SSMAgent/latest/linux_amd64/amazon-ssm-agent.rpm
          /opt/aws/bin/cfn-signal --exit-code $? \
                   --stack  ${AWS::StackName} \
                   --resource NodeGroup  \
                   --region ${AWS::Region}

Outputs:
  RDSEndpoint:
    Value: !GetAtt EksWorkDB.Endpoint.Address

</div></code></pre>
<p>postgresのバージョンが古かったから失敗するので調べておくこと</p>
<pre class="hljs"><code><div>$ aws rds describe-db-engine-versions --default-only --engine postgres
</div></code></pre>
<pre class="hljs"><code><div>$ aws rds describe-orderable-db-instance-options --engine postgres --engine-version 14.8 --query 'OrderableDBInstanceOptions[].[DBInstanceClass,StorageType,Engine,EngineVersion]' --output table --region ap-northeast-1
------------------------------------------------------
|         DescribeOrderableDBInstanceOptions         |
+-------------------+-----------+-----------+--------+
|  db.m5.12xlarge   |  gp2      |  postgres |  14.8  |
|  db.m5.12xlarge   |  gp3      |  postgres |  14.8  |
|  db.m5.12xlarge   |  io1      |  postgres |  14.8  |
|  db.m5.12xlarge   |  standard |  postgres |  14.8  |
...
|  db.t3.large      |  gp2      |  postgres |  14.8  |
|  db.t3.large      |  gp3      |  postgres |  14.8  |
|  db.t3.large      |  io1      |  postgres |  14.8  |
|  db.t3.large      |  standard |  postgres |  14.8  |
|  db.t3.medium     |  gp2      |  postgres |  14.8  |
|  db.t3.medium     |  gp3      |  postgres |  14.8  |
|  db.t3.medium     |  io1      |  postgres |  14.8  |
|  db.t3.medium     |  standard |  postgres |  14.8  |
|  db.t3.micro      |  gp2      |  postgres |  14.8  |
|  db.t3.micro      |  gp3      |  postgres |  14.8  |
|  db.t3.micro      |  io1      |  postgres |  14.8  |
|  db.t3.micro      |  standard |  postgres |  14.8  |
|  db.t3.small      |  gp2      |  postgres |  14.8  |
|  db.t3.small      |  gp3      |  postgres |  14.8  |
|  db.t3.small      |  io1      |  postgres |  14.8  |
...

</div></code></pre>
<p>Systems Manager -&gt; セッションマネージャーでセッションを開始する</p>
<pre class="hljs"><code><div>$ sudo yum install -y git
$ sudo amazon-linux-extras install -y postgresql10
</div></code></pre>
<p>データベースの以下の値を確認</p>
<ul>
<li>エンドポイントアドレス: CloudFormation 出力 RDSEndpoint</li>
<li>管理者用パスワード: Secrets Manager RdsMasterSecret</li>
<li>アプリケーション用データベースユーザのパスワード: Secrets Manager RdsUserSecret</li>
</ul>
<pre class="hljs"><code><div>$ createuser -d -U eksdbadmin -P -h eks-work-db.cl1b9exbukrt.ap-northeast-1.rds.amazonaws.com mywork
</div></code></pre>
<pre class="hljs"><code><div>$ createdb -U mywork -h eks-work-db.cl1b9exbukrt.ap-northeast-1.rds.amazonaws.com -E UTF8 myworkdb
</div></code></pre>
<p>接続</p>
<pre class="hljs"><code><div>$ psql -U mywork -h eks-work-db.cl1b9exbukrt.ap-northeast-1.rds.amazonaws.com myworkdb
</div></code></pre>
<p>10_ddl.sql</p>
<pre class="hljs"><code><div>CREATE TABLE region
(
  region_id          SERIAL PRIMARY KEY,
  region_name        VARCHAR(100) NOT NULL,
  creation_timestamp TIMESTAMP    NOT NULL
);

CREATE TABLE location
(
  location_id   BIGSERIAL PRIMARY KEY,
  location_name VARCHAR(200) NOT NULL,
  region_id     BIGINT       NOT NULL,
  note          TEXT,
  FOREIGN KEY (region_id) REFERENCES region (region_id)
);

CREATE TABLE batch_processing
(
  batch_name VARCHAR(20) PRIMARY KEY,
  last_execution_date_time TIMESTAMP
);

CREATE TABLE batch_processing_file
(
  batch_processing_file_id BIGSERIAL PRIMARY KEY,
  batch_name VARCHAR(20) NOT NULL,
  file_name VARCHAR(300) NOT NULL
);
</div></code></pre>
<p>20_insert_sample_data.sql</p>
<pre class="hljs"><code><div>-- REGION
INSERT INTO region (region_name, creation_timestamp)
VALUES ('北海道', current_timestamp);

INSERT INTO region (region_name, creation_timestamp)
VALUES ('東北', current_timestamp);

INSERT INTO region (region_name, creation_timestamp)
VALUES ('関東', current_timestamp);

INSERT INTO region (region_name, creation_timestamp)
VALUES ('中部', current_timestamp);

INSERT INTO region (region_name, creation_timestamp)
VALUES ('近畿', current_timestamp);

INSERT INTO region (region_name, creation_timestamp)
VALUES ('中国', current_timestamp);

INSERT INTO region (region_name, creation_timestamp)
VALUES ('四国', current_timestamp);

INSERT INTO region (region_name, creation_timestamp)
VALUES ('九州', current_timestamp);

INSERT INTO region (region_name, creation_timestamp)
VALUES ('沖縄', current_timestamp);

-- LOCATION
INSERT INTO location (location_name, region_id, note)
VALUES ('美ら海水族館', (SELECT region_id FROM region WHERE region_name = '沖縄'),
  '沖縄の代表的な水族館で、ジンベエザメをはじめ、様々な沖縄の海の生き物を見ることができます。');

INSERT INTO location (location_name, region_id, note)
VALUES ('首里城', (SELECT region_id FROM region WHERE region_name = '沖縄'),
  '琉球王朝の王城で、世界遺産の1つです。');

-- BATCH_PROCESSING
INSERT INTO batch_processing (batch_name)
values ('SAMPLE_APP_BATCH');
</div></code></pre>
<p>初期データ投入</p>
<pre class="hljs"><code><div>myworkdb=&gt; \i 10_ddl.sql
CREATE TABLE
CREATE TABLE
CREATE TABLE
CREATE TABLE
myworkdb=&gt; \i 20_insert_sample_data.sql
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
INSERT 0 1
</div></code></pre>
<h2 id="api%E3%81%AEcontainer-build%E3%81%A8push">APIのcontainer buildとpush</h2>
<p>Corretto をインストールした後、JAVA_HOMEの環境変数を設定</p>
<pre class="hljs"><code><div>export JAVA_HOME=$(/usr/libexec/java_home -v 11)
</div></code></pre>
<p>以下のコマンドでソースコードから実行可能jarを作成する</p>
<pre class="hljs"><code><div>$ ./gradlew clean build
</div></code></pre>
<p>実行可能ファイルは <code>backend-app-1.0.0.jar</code> という名前で配置している</p>
<p>Dockerfileがあるディレクトリでbuildコマンドを実行する</p>
<pre class="hljs"><code><div>$ docker build --platform amd64 -t k8sbook/backend-app:1.1.0 --build-arg JAR_FILE=backend-app-1.0.0.jar .
</div></code></pre>
<p>buildされた後の成果物</p>
<pre class="hljs"><code><div>$ docker images | grep &quot;k8sbook&quot;
k8sbook/backend-app                                  1.0.0       9d000b75dbae   4 days ago      516MB
</div></code></pre>
<p>Container Resistoryの準備してアップロードする</p>
<p>まず、Amazon ECRを用意する</p>
<p><img src="./repository.png" alt="ECR"></p>
<p>作成したもの</p>
<p><img src="./repository2.png" alt="ECR2"></p>
<p>ログインする</p>
<pre class="hljs"><code><div>$ aws ecr get-login-password --region ap-northeast-1 | docker login --username AWS --password-stdin 761624429622.dkr.ecr.ap-northeast-1.amazonaws.com
Login Succeeded
</div></code></pre>
<p>dockerのtag付けをする</p>
<pre class="hljs"><code><div>$ docker tag k8sbook/backend-app:1.0.0 761624429622.dkr.ecr.ap-northeast-1.amazonaws.com/k8sbook/backend-app:1.0.0
</div></code></pre>
<p>pushする</p>
<pre class="hljs"><code><div>$ docker push 761624429622.dkr.ecr.ap-northeast-1.amazonaws.com/k8sbook/backend-app:1.0.0
The push refers to repository [761624429622.dkr.ecr.ap-northeast-1.amazonaws.com/k8sbook/backend-app]
18e12aace9aa: Pushed 
f30dc1e9505b: Pushed 
e3bc576ca49a: Pushed 
19bf53d200d5: Pushed 
1.0.0: digest: sha256:dbc5d282f2cc8fb4e7027a1aa4a14d9e4054c2d46a19db7d08581f6e3b7a7084 size: 1161
</div></code></pre>
<p><img src="./container.png" alt="container"></p>
<h2 id="eks%E3%82%AF%E3%83%A9%E3%82%B9%E3%82%BF%E3%83%BC%E3%81%B8%E3%81%AE-api%E3%82%A2%E3%83%97%E3%83%AA%E3%82%B1%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3%E3%81%AE%E3%83%87%E3%83%97%E3%83%AD%E3%82%A4">EKSクラスターへの APIアプリケーションのデプロイ</h2>
<ul>
<li>Namespaceの作成</li>
<li>kubeconfigへのNamespaceの反映</li>
<li>データベース接続用のSecretの登録</li>
<li>APIアプリケーションのデプロイ</li>
<li>APIアプリケーションの公開</li>
</ul>
<p>20_create_namespace_k8s.yaml を用意</p>
<pre class="hljs"><code><div>apiVersion: v1
kind: Namespace
metadata:
  name: eks-work
</div></code></pre>
<p>kubectl を適用する</p>
<pre class="hljs"><code><div>$ kubectl apply -f 20_create_namespace_k8s.yaml
namespace/eks-work created
</div></code></pre>
<pre class="hljs"><code><div>$ kubectl config get-contexts
CURRENT   NAME                                                 CLUSTER                                       AUTHINFO                                             NAMESPACE
*         awscli@eks-worker-cluster.ap-northeast-1.eksctl.io   eks-worker-cluster.ap-northeast-1.eksctl.io   awscli@eks-worker-cluster.ap-northeast-1.eksctl.io 
</div></code></pre>
<p>上記コマンドのAUTHINFOとCLUSTER列を使用する</p>
<pre class="hljs"><code><div>$ AUTHINFO='awscli@eks-worker-cluster.ap-northeast-1.eksctl.io'
$ CLUSTER='eks-worker-cluster.ap-northeast-1.eksctl.io'
$ kubectl config set-context eks-work --cluster $CLUSTER --user $AUTHINFO --namespace eks-work
Context &quot;eks-work&quot; created.
[2023-07-04T05:28:54] okmt@mba:~/plays/aws/k8s_on_aws $ kubectl config use-context eks-work
Switched to context &quot;eks-work&quot;.
[2023-07-04T05:29:00] okmt@mba:~/plays/aws/k8s_on_aws $ kubectl config get-contexts
CURRENT   NAME                                                 CLUSTER                                       AUTHINFO                                             NAMESPACE
          awscli@eks-worker-cluster.ap-northeast-1.eksctl.io   eks-worker-cluster.ap-northeast-1.eksctl.io   awscli@eks-worker-cluster.ap-northeast-1.eksctl.io   
*         eks-work                                             eks-worker-cluster.ap-northeast-1.eksctl.io   awscli@eks-worker-cluster.ap-northeast-1.eksctl.io   eks-work
</div></code></pre>
<p>データベース接続用Secret作成</p>
<ul>
<li>RDSエンドポイントアドレス（CloudFormationの出力タブから取得）: 'eks-work-db.cl1b9exbukrt.ap-northeast-1.rds.amazonaws.com'</li>
<li>アプリケーション用データベースユーザのパスワード（Secret Managerの画面から取得）: ';1cg3bt0FAL)qiOC'</li>
</ul>
<pre class="hljs"><code><div>$ ENDPOINT='eks-work-db.cl1b9exbukrt.ap-northeast-1.rds.amazonaws.com' \
PASSWORD=';1cg3bt0FAL)qiOC' \
envsubst &lt; k8sbook/eks-env/21_db_config_k8s.yaml.template | \
kubectl apply -f - 

secret/db-config created
</div></code></pre>
<p>[補足] secretの削除方法</p>
<pre class="hljs"><code><div>$ kubectl get secrets
NAME        TYPE     DATA   AGE
db-config   Opaque   3      12h

$ kubectl delete secret db-config
secret &quot;db-config&quot; deleted
</div></code></pre>
<p>APIアプリケーションのデプロイ</p>
<pre class="hljs"><code><div>$ ECR_HOST='761624429622.dkr.ecr.ap-northeast-1.amazonaws.com' \ 
envsubst &lt; k8sbook/eks-env/22_deployment_backend-app_k8s.yaml.template | \
kubectl apply -f -

deployment.apps/backend-app created
deployment.apps/backend-app configured
</div></code></pre>
<p>コンポーネントの作成がうまく行かなかったとき</p>
<pre class="hljs"><code><div>$ kubectl get all
NAME                               READY   STATUS             RESTARTS   AGE
pod/backend-app-6c7d4794c8-ljsg4   0/1     InvalidImageName   0          3m12s
pod/backend-app-6c7d4794c8-xjrgt   0/1     InvalidImageName   0          3m12s

NAME                          READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/backend-app   0/2     2            0           3m13s

NAME                                     DESIRED   CURRENT   READY   AGE
replicaset.apps/backend-app-6c7d4794c8   2         2         0       3m13s
</div></code></pre>
<p>[補足] podの削除方法</p>
<pre class="hljs"><code><div>$ kubectl delete -f k8sbook/eks-env/22_deployment_backend-app_k8s.yaml.template 
deployment.apps &quot;backend-app&quot; deleted
</div></code></pre>
<p>コンポーネントの作成がうまく行った時は以下のようになる</p>
<pre class="hljs"><code><div>$ kubectl get all
NAME                              READY   STATUS    RESTARTS   AGE
pod/backend-app-89b68f9fc-gj94v   1/1     Running   0          88s
pod/backend-app-89b68f9fc-mrbn2   1/1     Running   0          96s

NAME                          READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/backend-app   2/2     2            2           30m

NAME                                    DESIRED   CURRENT   READY   AGE
replicaset.apps/backend-app-89b68f9fc   2         2         2       30m
</div></code></pre>
<p>APIアプリケーションの公開</p>
<pre class="hljs"><code><div>$ kubectl apply -f k8sbook/eks-env/23_service_backend-app_k8s.yaml 
service/backend-app-service created

$ kubectl get all
NAME                              READY   STATUS    RESTARTS   AGE
pod/backend-app-89b68f9fc-gj94v   1/1     Running   0          10m
pod/backend-app-89b68f9fc-mrbn2   1/1     Running   0          10m

NAME                          TYPE           CLUSTER-IP     EXTERNAL-IP                                                                  PORT(S)          AGE
service/backend-app-service   LoadBalancer   10.100.61.85   a159eb0af247f42e994342dab57d432a-47984927.ap-northeast-1.elb.amazonaws.com   8080:30893/TCP   4s

NAME                          READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/backend-app   2/2     2            2           38m

NAME                                    DESIRED   CURRENT   READY   AGE
replicaset.apps/backend-app-89b68f9fc   2         2         2       38m
</div></code></pre>
<p>EXTERNAL-IP列には「elb.amazonaws.com」で終わるアドレスが出力されている</p>
<p>ロードバランサーが出来上がっている</p>
<p><img src="./ec2lb.png" alt="el"></p>
<p>インスタンスタブを確認する</p>
<p><img src="./ec2lbinstance.png" alt="el"></p>
<p>EXTERNAL-IPの値を指定して動作確認できる</p>
<pre class="hljs"><code><div>$ curl -s http://a159eb0af247f42e994342dab57d432a-47984927.ap-northeast-1.elb.amazonaws.com:8080/health
{&quot;status&quot;:&quot;OK&quot;}
</div></code></pre>
<h2 id="%E3%83%95%E3%83%AD%E3%83%B3%E3%83%88%E3%82%A8%E3%83%B3%E3%83%89%E3%82%A2%E3%83%97%E3%83%AA%E3%82%B1%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3%E3%81%AE%E3%83%93%E3%83%AB%E3%83%89%E3%81%A8%E3%83%87%E3%83%97%E3%83%AD%E3%82%A4">フロントエンドアプリケーションのビルドとデプロイ</h2>
<p>a</p>

</body>
</html>
